dataset: # Required.
  type: cityscapes
  train:
    data_root: /home/ubuntu/HRNet-Semantic-Segmentation/data/cityscapes
    data_list: /home/ubuntu/HRNet-Semantic-Segmentation/data/list/cityscapes/train.lst
    flip: True
    GaussianBlur: False
    rand_resize: [0.5, 2.0]
    #rand_rotation: [-10.0, 10.0]
    crop:
      type: rand
      size: [769, 769] # crop image with HxW size
  val:
    data_root: /home/ubuntu/HRNet-Semantic-Segmentation/data/cityscapes
    data_list: /home/ubuntu/HRNet-Semantic-Segmentation/data/list/cityscapes/val.lst
    crop:
      type: center
      size: [769, 769] # crop image with HxW size
  batch_size: 2
  workers: 2
  mean: [123.675, 116.28, 103.53]
  std: [58.395, 57.12, 57.375]
  ignore_label: 255

trainer: # Required.
  epochs: 100
  start_epochs: 0
  eval_on: True
  optimizer:
    type: SGD
    kwargs:
      lr: 0.01
      momentum: 0.9
      weight_decay: 0.0005
  lr_scheduler:
    mode: poly
    kwargs:
      power: 0.9

saver:
  snapshot_dir: checkpoints
  pretrain: ''

criterion:
  type: ohem
  contrast_weight: 0.1
  kwargs:
    thresh: 0.7
    min_kept: 100000

net: # Required.
  num_classes: 19
  sync_bn: False
  aux_loss:
    aux_plane: 1024
    loss_weight: 0.4
  encoder:
    type: pyseg.models.resnet.resnet50
    kwargs:
      multi_grid: True
      zero_init_residual: True
      replace_stride_with_dilation: [False, True, True]  #layer0...1 is fixed, layer2...4
  decoder:
    type: pyseg.models.decoder_contrast.dec_deeplabv3_contrast
    kwargs:
      inner_planes: 256
      dilations: [12, 24, 36]
      
